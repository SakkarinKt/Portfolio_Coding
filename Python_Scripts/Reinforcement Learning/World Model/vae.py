# -*- coding: utf-8 -*-
"""VAE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1beRUZSlM1iBax7NSFCtGLbw_9rVl9sr1
"""

# Building Variational AutoEncode model
import torch
import torch.nn as nn
import torch.nn.functional as F

class Decoder(nn.Module):
  # VAE Decoder
  def __init__(self, img_channels, latent_size):
    super(Decoder, self).__init__()
    self.latent_size = latent_size
    self.img_channels = img_channels

    self.fc1 = nn.Linear(latent_size, 1024)
    self.deconv1 = nn.ConvTranspose2d(1024, 128, 5, stride = 2)
    self.deconv2 = nn.ConvTranspose2d(128, 64, 5, stride = 2)
    self.deconv3 = nn.ConvTranspose2d(64, 32, 6, stride = 2)
    self.deconv4 = nn.ConvTranspose2d(32, img_channels, 6, stride = 2)
  
  def forward(self, x):
    x = F.relu(self.fc1(x))
    x = x.unsqeeze(-1).unsqeeze(-1)
    x = F.relu(self.deconv1(x))
    x = F.relu(self.deconv2(x))
    x = F.relu(self.deconv3(x))
    reconstruction = F.sigmoid(self.deconv3(x))
    return reconstruction

class Encoder(nn.Module):
  # VAE Encoder
  def __init__(self, img_channels, latent_size):
    super(Encoder, self).__init__()
    self.latent_size = latent_size
    self.img_channels = img_channels

    self.conv1 = nn.Conv2d(img_channels, 32, 4, stride = 2)
    self.conv2 = nn.Conv2d(32, 64, 4, stride = 2)
    self.conv3 = nn.Conv2d(64, 128, 4, stride = 2)
    self.conv4 = nn.Conv2d(128, 256, 4, stride = 2)

    self.fc_mu = nn.Linear(2*2*256, latent_size)
    self.fc_logsigma = nn.Linear(2*2*256, latent_size)

  def forward(self, x):
    x = F.relu(self.conv1(x))
    x = F.relu(self.conv2(x))
    x = F.relu(self.conv3(x))
    x = F.relu(self.conv4(x))
    x = x.view(x.size(0), -1)

    mu = self.fc_mu(x)
    logsigma = self.fc_log(x)

    return mu, logsigma

class VAE(nn.Module):

  def __init__(self, img_channels, latent_size):
    super(VAE, self).__init__()
    self.encoder = Encoder(img_channels, latent_size)
    self.decoder = Decoder(img_channels, latent_size)

  def forward(self, x):
    mu, log_sigma = self.encoder(x)
    sigma = logsigma.exp()
    eps = torch.randn_like(sigma)
    z = eps.mul(sigma).add_(mu)

    recon_x = self.decoder(z)
    return recon_x, mu, logsigma

# Training VAE

import argparse
from os.path import join, exists
from os import mkdir

import torch.utils.data
from torch import optim
from torch.nn import functional as F
from torchvision import transforms
from torchvision.utils import save_image

from utils.misc import save_checkpoint
from utils.misc import LSIZE, RED_SIZE
# Warninig this should be replaced by pytorch 0.5
from utils.learning import EarlyStopping
from utils.learning import ReduceLROnPlateau
from data.loaders import RolloutObservationDataset

parser = argparse.ArgumentParser(description = 'VAE trainer')
parser.add_argument('--batchsize', type = int, default = 32, metavar = 'N',
                    help = 'Input batch size for training (default:32)')
parser.add_argument('--epochs', type = int, default = 1000, metarvar = 'N',
                    help = 'Number of epochs to train (default:1000)')
parser.add_argument('--log_dir', type = str, help = 'Directory where results are logged')
parser.add_argument('--noreload',action = 'store_true', help = 'Best model is not reloaded if specified')
parser.add_argument('--nosamples',action = 'store_true', help = 'Does not have samples during training if specified')

args = parser.parse_args()
cuda = torch.cuda.is_available()

torch.manual_seed(123)
# Fix numeric divergence due to bug in cudnn
torch.backends.cudnn.benchmark = True

device = torch.device("cuda" if cuda else "cpu")

transform_train = transforms.Compose([
                                      transforms.ToPILImage(),
                                      transforms.Resize((RED_SIZE, RED_SIZE)),
                                      transforms.RandomHorizontalFlip(),
                                      transforms.ToTensor(),])
transform_test = transforms.Compose([
                                      transforms.ToPILImage(),
                                      transforms.Resize((RED_SIZE, RED_SIZE)),
                                      transforms.ToTensor(),])

dataset_train = RolloutObservationDataset('dataset/carracing',transform_train, train=True)
dataset_test = RolloutObservationDataset('dataset/carracing',transform_test, train=False)

train_loader = torch.utils.data.DataLoader(dataset_train, batch_size = args.batch_size, shuffle = True, num_workers = 2)
test_loader = torch.utils.data.DataLoader(dataset_test, batch_size = args.batch_size, shuffle = True, num_workers = 2)

model = VAE(3, LSIZE).to(device)
optimizer = optim.Adam(model.parameters())
scheduler = ReduceLROnPlateau(optimizer, 'min', factor = 0.5, patience = 5)
earlystopping = EarlyStopping('min', patience = 30)

# Reconstruction + KL divergence losses summed over all elements and batch
def loss_function(recon_x, x, mu, logsigma):
  """ VAE loss fuction """
  BCE = F.mse_loss(recon_x, x,size_average = False)
  KLD = -0.5 * torch.sum(1 + 2 * logsigma - mu.pow(2) - (2 * logsigma).exp())
  return BCE + KLD

def train(epoch):
  model.train()
  dataset_train.load_next_buffer()
  train_loss = 0
  for batch_idx, data in enumerate(train_loader):
    data = data.to(device)
    optimizer.zero_grad()
    recon_batch, mu, logvar = model(data)
    loss = loss_function(recon_batch, data, mu, logvar)
    loss.backword()
    train_loss += loss.item()
    optimizer.step()
    if batch_idx % 20 == 0:
      print('Train Epoch: {} [{}/{} ({:.0f}%)]\tloss: {:.6f}'.format(
          epoch, batch_idx * len(data), len(train_loader.dataset),
          100. * batch_idx / len(train_loader),
          loss.item() / len(data)))
  
  print('====> Epoch: {} Average loss: {.4f}'.format(
      epoch, train_loss / len(train_loader.dataset)))
  
def test():
  model.eval()
  dataset_test.load_next_buffer()
  test_loss = 0
  with torch.no_grad():
    for data in test_loader:
      data = data.to(device)
      recon_batch, mu, logvar = model(data)
      test_loss += loss_function(recon_batch,data,mu, logvar).item()

  test_loss /= len(test_loader.dataset)
  print('===> Test set loss: {:.4f}'.format(test_loss))
  return test_loss

# check VAE dir exist?, if not create it
vae_dir = join(args.logdir, 'vae')
if not exists(vae_dir):
  mkdir(vae_dir)
  mkdir(join(vae_dir,'samples'))

reload_file = join(vae_dir, 'best.tar')

if not args.noreload and exists(reload_file):
  state = torch.load(reload_file)
  print('Reloading model at epoch {}'', with test error {}'.format(
      state['epoch'],state['precision']))
  model.load_state_dict(state['state_dict'])
  optimizer.load_state_dict(state['optimizer'])
  scheduler.load_state_dict(state['scheduler'])
  earlystopping.load_state_dict(state['earlystopping'])

cur_best = None
for epoch in range(1, args.epochs + 1):
  train(epoch)
  test_loss = test()
  scheduler.step(test_loss)
  earlystopping.step(test_loss)

  # checkpointing
  best_filename = join(vae_dir, 'best.tar')
  filename = join(vae_dir, 'checkpoint.tar')
  is_best = not cur_best or test_loss < cur_best
  if is_best:
    cur_best = test_loss

  save_checkpoint({
      'epoch': epoch,
      'state_dict': model.state_dict(),
      'precision': test_loss,
      'optimizer': optimizer.state_dict(),
      'scheduler': scheduler.state_dict(),
      'earlystopping': earlystopping.state_dict()}, is_best, filename, best_filename)
  
  if not args.nosamples:
    with torch.no_grad():
      sample = torch.randn(RED_SIZE, LSIZE).to(device)
      sample = model.decoder(sample).cpu()
      save_image(sample.view(64,3, RED_SIZE, LSIZE), join(vae_dir, 'samples/sample_' + str(epoch) + '.png'))

  if earlystopping.stop:
    print("End of training because of early stopping at epoch {}".format(epoch))
    break